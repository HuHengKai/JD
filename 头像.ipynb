{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "头像.ipynb",
      "provenance": [],
      "mount_file_id": "1PNE9fJStrb8iN7m5K-6rzNzKEhbRLA9v",
      "authorship_tag": "ABX9TyMguDZP3u+Cin1xcmu8PhyC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuHengKai/JD/blob/master/%E5%A4%B4%E5%83%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-ZeqwaBy6Pu",
        "outputId": "fc550839-1544-4efa-9606-17bfa2fe31cc"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class DCGAN():\n",
        "    def __init__(self):\n",
        "        # 输入shape\n",
        "        self.img_rows = 64\n",
        "        self.img_cols = 64\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "        # adam优化器\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        # 判别模型\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "        # 生成模型\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # conbine是生成模型和判别模型的结合\n",
        "        # 判别模型的trainable为False\n",
        "        # 用于训练生成模型\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        valid = self.discriminator(img)\n",
        "\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_generator(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(256 * 8 * 8, activation='relu', input_dim=self.latent_dim))  # 输入维度为100\n",
        "        model.add(Reshape((8, 8, 256)))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, kernel_size=5, padding='same'))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(64, kernel_size=5, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(3, kernel_size=5, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "        model.summary()  # 打印网络参数\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        model = Sequential()\n",
        "        dropout = 0.5\n",
        "        model.add(Conv2D(64, kernel_size=5, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(Conv2D(256, kernel_size=5, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(dropout))\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.summary()\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, save_interval=50):\n",
        "        # 载入数据\n",
        "        filename = \"/content/drive/MyDrive/机器学习展示/data/\"\n",
        "        X_train = load_image(filename)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # --------------------- #\n",
        "            #  训练判别模型\n",
        "            # --------------------- #\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            # 训练并计算loss\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ---------------------\n",
        "            #  训练生成模型\n",
        "            # ---------------------\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "            if epoch % save_interval == 0:\n",
        "                self.save_imgs(epoch)\n",
        "\n",
        "    def save_imgs(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"dc_images/MeganFaces_%d.png\" % epoch)\n",
        "        plt.close()\n",
        "\n",
        "def load_image(filename):\n",
        "    imgs = os.listdir(filename)[:10]\n",
        "    print(len(imgs))\n",
        "    x_train = np.empty((imgs.__len__(), 64, 64, 3), dtype='float32')\n",
        "\n",
        "    for i in range(len(imgs)):\n",
        "        img = Image.open(filename + imgs[i])\n",
        "        img = img.resize((64,64))\n",
        "        img_arr = np.asarray(img, dtype='float32')\n",
        "        x_train[i, :, :, :] = img_arr/127.5 - 1.\n",
        "\n",
        "    return x_train\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists(\"./dc_images\"):\n",
        "        os.makedirs(\"./dc_images\")\n",
        "    dcgan = DCGAN()\n",
        "    dcgan.train(epochs=20000, batch_size=256, save_interval=50)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 64)        4864      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 256)         819456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 1,031,041\n",
            "Trainable params: 1,030,273\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 16384)             1654784   \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 128)       819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 64, 64, 3)         4803      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64, 64, 3)         0         \n",
            "=================================================================\n",
            "Total params: 2,684,547\n",
            "Trainable params: 2,684,163\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "10\n",
            "0 [D loss: 0.725609, acc.: 49.61%] [G loss: 0.669917]\n",
            "1 [D loss: 0.720083, acc.: 49.41%] [G loss: 0.665727]\n",
            "2 [D loss: 0.724339, acc.: 39.26%] [G loss: 0.590420]\n",
            "3 [D loss: 0.765963, acc.: 28.32%] [G loss: 0.525945]\n",
            "4 [D loss: 0.712625, acc.: 46.09%] [G loss: 0.512016]\n",
            "5 [D loss: 0.714581, acc.: 49.41%] [G loss: 0.578990]\n",
            "6 [D loss: 0.711787, acc.: 49.61%] [G loss: 0.607747]\n",
            "7 [D loss: 0.713755, acc.: 49.02%] [G loss: 0.516611]\n",
            "8 [D loss: 0.706095, acc.: 50.59%] [G loss: 0.466248]\n",
            "9 [D loss: 0.713061, acc.: 48.83%] [G loss: 0.428888]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLsllXoDzW5q"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dense, BatchNormalization, LeakyReLU, Input,Reshape, MaxPooling2D, Flatten, AveragePooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adIv31CGQyOu",
        "outputId": "b56986e3-60f3-46e8-dc35-1684e33a4cb9"
      },
      "source": [
        "#加载数据集\n",
        "# 数据集的位置 496\n",
        "avatar_img_path = \"/content/drive/MyDrive/机器学习展示/data/\"\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import os\n",
        "import numpy as np\n",
        "def load_image(filename):\n",
        "    imgs = os.listdir(filename)\n",
        "    x_train = np.empty((imgs.__len__(), 64, 64, 3), dtype='float32')\n",
        "\n",
        "    for i in range(len(imgs)):\n",
        "        if i%30==0:\n",
        "          print(i)\n",
        "        img = Image.open(filename + imgs[i])\n",
        "        img = img.resize((64,64))\n",
        "        img_arr = np.asarray(img, dtype='float32')\n",
        "        x_train[i, :, :, :] = img_arr/127.5 - 1.\n",
        "\n",
        "    return x_train\n",
        "dataset=load_image(avatar_img_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "30\n",
            "60\n",
            "90\n",
            "120\n",
            "150\n",
            "180\n",
            "210\n",
            "240\n",
            "270\n",
            "300\n",
            "330\n",
            "360\n",
            "390\n",
            "420\n",
            "450\n",
            "480\n",
            "510\n",
            "540\n",
            "570\n",
            "600\n",
            "630\n",
            "660\n",
            "690\n",
            "720\n",
            "750\n",
            "780\n",
            "810\n",
            "840\n",
            "870\n",
            "900\n",
            "930\n",
            "960\n",
            "990\n",
            "1020\n",
            "1050\n",
            "1080\n",
            "1110\n",
            "1140\n",
            "1170\n",
            "1200\n",
            "1230\n",
            "1260\n",
            "1290\n",
            "1320\n",
            "1350\n",
            "1380\n",
            "1410\n",
            "1440\n",
            "1470\n",
            "1500\n",
            "1530\n",
            "1560\n",
            "1590\n",
            "1620\n",
            "1650\n",
            "1680\n",
            "1710\n",
            "1740\n",
            "1770\n",
            "1800\n",
            "1830\n",
            "1860\n",
            "1890\n",
            "1920\n",
            "1950\n",
            "1980\n",
            "2010\n",
            "2040\n",
            "2070\n",
            "2100\n",
            "2130\n",
            "2160\n",
            "2190\n",
            "2220\n",
            "2250\n",
            "2280\n",
            "2310\n",
            "2340\n",
            "2370\n",
            "2400\n",
            "2430\n",
            "2460\n",
            "2490\n",
            "2520\n",
            "2550\n",
            "2580\n",
            "2610\n",
            "2640\n",
            "2670\n",
            "2700\n",
            "2730\n",
            "2760\n",
            "2790\n",
            "2820\n",
            "2850\n",
            "2880\n",
            "2910\n",
            "2940\n",
            "2970\n",
            "3000\n",
            "3030\n",
            "3060\n",
            "3090\n",
            "3120\n",
            "3150\n",
            "3180\n",
            "3210\n",
            "3240\n",
            "3270\n",
            "3300\n",
            "3330\n",
            "3360\n",
            "3390\n",
            "3420\n",
            "3450\n",
            "3480\n",
            "3510\n",
            "3540\n",
            "3570\n",
            "3600\n",
            "3630\n",
            "3660\n",
            "3690\n",
            "3720\n",
            "3750\n",
            "3780\n",
            "3810\n",
            "3840\n",
            "3870\n",
            "3900\n",
            "3930\n",
            "3960\n",
            "3990\n",
            "4020\n",
            "4050\n",
            "4080\n",
            "4110\n",
            "4140\n",
            "4170\n",
            "4200\n",
            "4230\n",
            "4260\n",
            "4290\n",
            "4320\n",
            "4350\n",
            "4380\n",
            "4410\n",
            "4440\n",
            "4470\n",
            "4500\n",
            "4530\n",
            "4560\n",
            "4590\n",
            "4620\n",
            "4650\n",
            "4680\n",
            "4710\n",
            "4740\n",
            "4770\n",
            "4800\n",
            "4830\n",
            "4860\n",
            "4890\n",
            "4920\n",
            "4950\n",
            "4980\n",
            "5010\n",
            "5040\n",
            "5070\n",
            "5100\n",
            "5130\n",
            "5160\n",
            "5190\n",
            "5220\n",
            "5250\n",
            "5280\n",
            "5310\n",
            "5340\n",
            "5370\n",
            "5400\n",
            "5430\n",
            "5460\n",
            "5490\n",
            "5520\n",
            "5550\n",
            "5580\n",
            "5610\n",
            "5640\n",
            "5670\n",
            "5700\n",
            "5730\n",
            "5760\n",
            "5790\n",
            "5820\n",
            "5850\n",
            "5880\n",
            "5910\n",
            "5940\n",
            "5970\n",
            "6000\n",
            "6030\n",
            "6060\n",
            "6090\n",
            "6120\n",
            "6150\n",
            "6180\n",
            "6210\n",
            "6240\n",
            "6270\n",
            "6300\n",
            "6330\n",
            "6360\n",
            "6390\n",
            "6420\n",
            "6450\n",
            "6480\n",
            "6510\n",
            "6540\n",
            "6570\n",
            "6600\n",
            "6630\n",
            "6660\n",
            "6690\n",
            "6720\n",
            "6750\n",
            "6780\n",
            "6810\n",
            "6840\n",
            "6870\n",
            "6900\n",
            "6930\n",
            "6960\n",
            "6990\n",
            "7020\n",
            "7050\n",
            "7080\n",
            "7110\n",
            "7140\n",
            "7170\n",
            "7200\n",
            "7230\n",
            "7260\n",
            "7290\n",
            "7320\n",
            "7350\n",
            "7380\n",
            "7410\n",
            "7440\n",
            "7470\n",
            "7500\n",
            "7530\n",
            "7560\n",
            "7590\n",
            "7620\n",
            "7650\n",
            "7680\n",
            "7710\n",
            "7740\n",
            "7770\n",
            "7800\n",
            "7830\n",
            "7860\n",
            "7890\n",
            "7920\n",
            "7950\n",
            "7980\n",
            "8010\n",
            "8040\n",
            "8070\n",
            "8100\n",
            "8130\n",
            "8160\n",
            "8190\n",
            "8220\n",
            "8250\n",
            "8280\n",
            "8310\n",
            "8340\n",
            "8370\n",
            "8400\n",
            "8430\n",
            "8460\n",
            "8490\n",
            "8520\n",
            "8550\n",
            "8580\n",
            "8610\n",
            "8640\n",
            "8670\n",
            "8700\n",
            "8730\n",
            "8760\n",
            "8790\n",
            "8820\n",
            "8850\n",
            "8880\n",
            "8910\n",
            "8940\n",
            "8970\n",
            "9000\n",
            "9030\n",
            "9060\n",
            "9090\n",
            "9120\n",
            "9150\n",
            "9180\n",
            "9210\n",
            "9240\n",
            "9270\n",
            "9300\n",
            "9330\n",
            "9360\n",
            "9390\n",
            "9420\n",
            "9450\n",
            "9480\n",
            "9510\n",
            "9540\n",
            "9570\n",
            "9600\n",
            "9630\n",
            "9660\n",
            "9690\n",
            "9720\n",
            "9750\n",
            "9780\n",
            "9810\n",
            "9840\n",
            "9870\n",
            "9900\n",
            "9930\n",
            "9960\n",
            "9990\n",
            "10020\n",
            "10050\n",
            "10080\n",
            "10110\n",
            "10140\n",
            "10170\n",
            "10200\n",
            "10230\n",
            "10260\n",
            "10290\n",
            "10320\n",
            "10350\n",
            "10380\n",
            "10410\n",
            "10440\n",
            "10470\n",
            "10500\n",
            "10530\n",
            "10560\n",
            "10590\n",
            "10620\n",
            "10650\n",
            "10680\n",
            "10710\n",
            "10740\n",
            "10770\n",
            "10800\n",
            "10830\n",
            "10860\n",
            "10890\n",
            "10920\n",
            "10950\n",
            "10980\n",
            "11010\n",
            "11040\n",
            "11070\n",
            "11100\n",
            "11130\n",
            "11160\n",
            "11190\n",
            "11220\n",
            "11250\n",
            "11280\n",
            "11310\n",
            "11340\n",
            "11370\n",
            "11400\n",
            "11430\n",
            "11460\n",
            "11490\n",
            "11520\n",
            "11550\n",
            "11580\n",
            "11610\n",
            "11640\n",
            "11670\n",
            "11700\n",
            "11730\n",
            "11760\n",
            "11790\n",
            "11820\n",
            "11850\n",
            "11880\n",
            "11910\n",
            "11940\n",
            "11970\n",
            "12000\n",
            "12030\n",
            "12060\n",
            "12090\n",
            "12120\n",
            "12150\n",
            "12180\n",
            "12210\n",
            "12240\n",
            "12270\n",
            "12300\n",
            "12330\n",
            "12360\n",
            "12390\n",
            "12420\n",
            "12450\n",
            "12480\n",
            "12510\n",
            "12540\n",
            "12570\n",
            "12600\n",
            "12630\n",
            "12660\n",
            "12690\n",
            "12720\n",
            "12750\n",
            "12780\n",
            "12810\n",
            "12840\n",
            "12870\n",
            "12900\n",
            "12930\n",
            "12960\n",
            "12990\n",
            "13020\n",
            "13050\n",
            "13080\n",
            "13110\n",
            "13140\n",
            "13170\n",
            "13200\n",
            "13230\n",
            "13260\n",
            "13290\n",
            "13320\n",
            "13350\n",
            "13380\n",
            "13410\n",
            "13440\n",
            "13470\n",
            "13500\n",
            "13530\n",
            "13560\n",
            "13590\n",
            "13620\n",
            "13650\n",
            "13680\n",
            "13710\n",
            "13740\n",
            "13770\n",
            "13800\n",
            "13830\n",
            "13860\n",
            "13890\n",
            "13920\n",
            "13950\n",
            "13980\n",
            "14010\n",
            "14040\n",
            "14070\n",
            "14100\n",
            "14130\n",
            "14160\n",
            "14190\n",
            "14220\n",
            "14250\n",
            "14280\n",
            "14310\n",
            "14340\n",
            "14370\n",
            "14400\n",
            "14430\n",
            "14460\n",
            "14490\n",
            "14520\n",
            "14550\n",
            "14580\n",
            "14610\n",
            "14640\n",
            "14670\n",
            "14700\n",
            "14730\n",
            "14760\n",
            "14790\n",
            "14820\n",
            "14850\n",
            "14880\n",
            "14910\n",
            "14940\n",
            "14970\n",
            "15000\n",
            "15030\n",
            "15060\n",
            "15090\n",
            "15120\n",
            "15150\n",
            "15180\n",
            "15210\n",
            "15240\n",
            "15270\n",
            "15300\n",
            "15330\n",
            "15360\n",
            "15390\n",
            "15420\n",
            "15450\n",
            "15480\n",
            "15510\n",
            "15540\n",
            "15570\n",
            "15600\n",
            "15630\n",
            "15660\n",
            "15690\n",
            "15720\n",
            "15750\n",
            "15780\n",
            "15810\n",
            "15840\n",
            "15870\n",
            "15900\n",
            "15930\n",
            "15960\n",
            "15990\n",
            "16020\n",
            "16050\n",
            "16080\n",
            "16110\n",
            "16140\n",
            "16170\n",
            "16200\n",
            "16230\n",
            "16260\n",
            "16290\n",
            "16320\n",
            "16350\n",
            "16380\n",
            "16410\n",
            "16440\n",
            "16470\n",
            "16500\n",
            "16530\n",
            "16560\n",
            "16590\n",
            "16620\n",
            "16650\n",
            "16680\n",
            "16710\n",
            "16740\n",
            "16770\n",
            "16800\n",
            "16830\n",
            "16860\n",
            "16890\n",
            "16920\n",
            "16950\n",
            "16980\n",
            "17010\n",
            "17040\n",
            "17070\n",
            "17100\n",
            "17130\n",
            "17160\n",
            "17190\n",
            "17220\n",
            "17250\n",
            "17280\n",
            "17310\n",
            "17340\n",
            "17370\n",
            "17400\n",
            "17430\n",
            "17460\n",
            "17490\n",
            "17520\n",
            "17550\n",
            "17580\n",
            "17610\n",
            "17640\n",
            "17670\n",
            "17700\n",
            "17730\n",
            "17760\n",
            "17790\n",
            "17820\n",
            "17850\n",
            "17880\n",
            "17910\n",
            "17940\n",
            "17970\n",
            "18000\n",
            "18030\n",
            "18060\n",
            "18090\n",
            "18120\n",
            "18150\n",
            "18180\n",
            "18210\n",
            "18240\n",
            "18270\n",
            "18300\n",
            "18330\n",
            "18360\n",
            "18390\n",
            "18420\n",
            "18450\n",
            "18480\n",
            "18510\n",
            "18540\n",
            "18570\n",
            "18600\n",
            "18630\n",
            "18660\n",
            "18690\n",
            "18720\n",
            "18750\n",
            "18780\n",
            "18810\n",
            "18840\n",
            "18870\n",
            "18900\n",
            "18930\n",
            "18960\n",
            "18990\n",
            "19020\n",
            "19050\n",
            "19080\n",
            "19110\n",
            "19140\n",
            "19170\n",
            "19200\n",
            "19230\n",
            "19260\n",
            "19290\n",
            "19320\n",
            "19350\n",
            "19380\n",
            "19410\n",
            "19440\n",
            "19470\n",
            "19500\n",
            "19530\n",
            "19560\n",
            "19590\n",
            "19620\n",
            "19650\n",
            "19680\n",
            "19710\n",
            "19740\n",
            "19770\n",
            "19800\n",
            "19830\n",
            "19860\n",
            "19890\n",
            "19920\n",
            "19950\n",
            "19980\n",
            "20010\n",
            "20040\n",
            "20070\n",
            "20100\n",
            "20130\n",
            "20160\n",
            "20190\n",
            "20220\n",
            "20250\n",
            "20280\n",
            "20310\n",
            "20340\n",
            "20370\n",
            "20400\n",
            "20430\n",
            "20460\n",
            "20490\n",
            "20520\n",
            "20550\n",
            "20580\n",
            "20610\n",
            "20640\n",
            "20670\n",
            "20700\n",
            "20730\n",
            "20760\n",
            "20790\n",
            "20820\n",
            "20850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX57zILdToEJ"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOU-I6N7QyL-"
      },
      "source": [
        "Batch_Size=50\n",
        "Buffer_Size=20000\n",
        "# 生成使用得数据集\n",
        "dataset=tf.data.Dataset.from_tensor_slices(dataset).shuffle(Buffer_Size).batch(Batch_Size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmTXfXSCQyGW"
      },
      "source": [
        "def generator_model():\n",
        "    model=tf.keras.Sequential()\n",
        "    model.add(layers.Dense(2048,input_shape=(100,),use_bias=False))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    # 全连接层 2048 ->  8 * 8 * 256\n",
        "    model.add(Dense(8 * 8 * 256))\n",
        "    # DN层\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    # 8 * 8 * 256 -> (8,8,256)\n",
        "    model.add(Reshape((8, 8, 256)))\n",
        "    # 卷积层 (8,8,256) -> (8,8,128)\n",
        "    model.add(Conv2D(128, kernel_size=5, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    # 反卷积层 (8,8,128) -> (16,16,128)\n",
        "    model.add(Conv2DTranspose(128, kernel_size=5, strides=2, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    # 反卷积层 (16,16,128) -> (32,32,64)\n",
        "    model.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    # 反卷积层  (32,32,64) -> (64,64,3) = 图片\n",
        "    model.add(Conv2DTranspose(3, kernel_size=5, strides=2, padding='same', activation='tanh'))\n",
        "    return model\n",
        "\n",
        "# 定义鉴别器\n",
        "def discriminator_model():\n",
        "    model = Sequential()\n",
        "    # 卷积层\n",
        "    model.add(Conv2D(64, kernel_size=5, padding='valid',input_shape = (64,64,3)))\n",
        "    # BN层\n",
        "    model.add(BatchNormalization())\n",
        "    # 激活层\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    # 平均池化层\n",
        "    model.add(AveragePooling2D(pool_size=2))\n",
        "    # 卷积层\n",
        "    model.add(Conv2D(128, kernel_size=3, padding='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(AveragePooling2D(pool_size=2))\n",
        "    model.add(Conv2D(256, kernel_size=3, padding='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(AveragePooling2D(pool_size=2))\n",
        "    # 将输入展平\n",
        "    model.add(Flatten())\n",
        "    # 全连接层\n",
        "    model.add(Dense(1024))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    # 最终输出1(true img) 0(fake img)的概率大小\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "# 定义损失,带有logit得交叉损失\n",
        "cross_entropy=keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "# 定义鉴别器损失\n",
        "def discriminator_loss(real_out,fake_out):\n",
        "  real_loss=cross_entropy(tf.ones_like(real_out),real_out)\n",
        "  fake_loss=cross_entropy(tf.zeros_like(fake_out),fake_out)\n",
        "  return real_loss+fake_loss\n",
        "# 定义生成器损失\n",
        "def generator_loss(fake_out):\n",
        "    fake_loss = cross_entropy(tf.ones_like(fake_out), fake_out)\n",
        "    return fake_loss\n",
        "# 寻优标准\n",
        "generator_opt=tf.keras.optimizers.Adam(0.0001)\n",
        "discriminator_opt=tf.keras.optimizers.Adam(0.0001)\n",
        "Epochs=100\n",
        "input_dim=100\n",
        "num_exp_to_generate=16\n",
        "# shape=(16, 100)\n",
        "seed=tf.random.normal([num_exp_to_generate,input_dim])\n",
        "# 模型实例化\n",
        "generator=generator_model()\n",
        "discriminator=discriminator_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA5yqrUiQyDm"
      },
      "source": [
        "def train_step(images):\n",
        "    noise=tf.random.normal([Batch_Size,input_dim])\n",
        "    with tf.GradientTape() as gen_tape,tf.GradientTape() as dis_tape:\n",
        "        real_out=discriminator(images)\n",
        "        gen_img =generator(noise)\n",
        "        fake_out=discriminator(gen_img)\n",
        "        dis_loss=discriminator_loss(real_out,fake_out)\n",
        "        gen_loss=generator_loss(fake_out)\n",
        " \n",
        "    gen_gard=gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
        "    dis_gard = dis_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
        "    discriminator_opt.apply_gradients(zip(dis_gard,discriminator.trainable_variables))\n",
        "    generator_opt.apply_gradients(zip(gen_gard, generator.trainable_variables))\n",
        " \n",
        "def genrate_plot_image(gen_model,test_noise):\n",
        "    pre_images=gen_model(test_noise,training=False)\n",
        "    fig=plt.figure(figsize=(4,4))\n",
        "    print(pre_images.shape[0])\n",
        "    for i in range(pre_images.shape[0]):\n",
        "        plt.subplot(4,4,i+1)\n",
        "        plt.imshow((pre_images[i,:,:,0]+1)/2*255.)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        " \n",
        "def train(dataset,epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "        print(epoch)\n",
        "        genrate_plot_image(generator,seed)\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    train(dataset,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt_yzVLgQyAm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MwbyY5RQx6o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}